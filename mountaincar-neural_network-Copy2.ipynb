{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatami\n",
    "\n",
    "I am a simple experiment on using qlearning agent setup for MountainCar problem.\n",
    "Being off-policy value based algorithm, qlearning has comparatively poor convergence on this problem (see a2c nearby for comparison) yet it does manage to find some policy that brings him to the end.\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "GAME = \"MountainCar-v0\"\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-06 16:29:43,840] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.92027520e-01  -4.94009357e-04]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(GAME)\n",
    "env.reset()\n",
    "obs = env.step(0)[0]\n",
    "action_names = np.array([\"left\",'stop',\"right\"]) #i guess so... i may be wrong\n",
    "state_size = len(obs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1133e0c18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8lFAnHIAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112de8b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using shallow neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer,DenseLayer, DropoutLayer\n",
    "\n",
    "\n",
    "inp = InputLayer((None,len(env.reset())), name=\"input\")\n",
    "h1 = DenseLayer(inp,1000,nonlinearity= lasagne.nonlinearities.sigmoid, name=\"h1\")\n",
    "h2 = DenseLayer(h1,1000, nonlinearity= lasagne.nonlinearities.sigmoid, name=\"h2\")\n",
    "d1 = DropoutLayer(h2, p=0.1, name=\"d1\")\n",
    "h3 = DenseLayer(d1, 100, nonlinearity=lasagne.nonlinearities.sigmoid, name=\"h3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "qvalues_layer = DenseLayer(h3,env.action_space.n,nonlinearity=lambda x:x, name=\"q\")\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n",
    "\n",
    "action_layer.epsilon.set_value(np.float32(0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=inp,\n",
    "              policy_estimators=qvalues_layer,\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[h1.W, h1.b, h2.W, h2.b, h3.W, h3.b, q.W, q.b]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-06 16:30:05,680] Making new env: MountainCar-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,GAME, N_AGENTS,max_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['right' 'right' 'right' 'right' 'right' 'right' 'stop']]\n",
      "[[-1. -1. -1. -1. -1. -1.  0.]]\n",
      "CPU times: user 8.83 ms, sys: 2.27 ms, total: 11.1 ms\n",
      "Wall time: 6.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_names[action_log])\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.experience_replay.actions[0].get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexajax/anaconda3/lib/python3.5/site-packages/agentnet/agent/mdp_agent.py:142: UserWarning: optimize_experience_replay is deprecated and will be removed in 1.0.2. Use experience_replay parameter.\n",
      "  warn(\"optimize_experience_replay is deprecated and will be removed in 1.0.2. Use experience_replay parameter.\")\n"
     ]
    }
   ],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,qvalues_seq = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#crop rewards to [-1,+1] to avoid explosion.\n",
    "#import theano.tensor as T\n",
    "#rewards = T.maximum(-1,T.minimum(rewards,1))\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.sgd(loss,weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydot_ng, pydot, pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.d3viz as d3v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at ~/train_step.png\n"
     ]
    }
   ],
   "source": [
    "theano.printing.pydotprint(train_step, \"~/train_step.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-06 16:30:23,026] Making new env: MountainCar-v0\n",
      "[2017-01-06 16:30:23,036] Attempted to wrap env <MountainCarEnv instance> after .configure() was called. All wrappers must be applied before calling .configure()\n",
      "[2017-01-06 16:30:23,037] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-06 16:30:23,039] Starting new video recorder writing to /Users/alexajax/Downloads/goto/records/openaigym.video.0.99355.video000000.mp4\n",
      "[2017-01-06 16:30:27,250] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alexajax/Downloads/goto/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=-200.0\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.8837.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "video_path=\"./records/openaigym.video.0.8837.video000000.mp4\"\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 133.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#pre-fill pool\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    pool.update(SEQ_LENGTH,append=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 499/5000 [15:46<2:16:43,  1.82s/it][2017-01-06 16:46:28,932] Making new env: MountainCar-v0\n",
      "[2017-01-06 16:46:28,943] Attempted to wrap env <MountainCarEnv instance> after .configure() was called. All wrappers must be applied before calling .configure()\n",
      "[2017-01-06 16:46:28,944] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-06 16:46:30,523] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alexajax/Downloads/goto/records')\n",
      " 10%|█         | 500/5000 [15:50<2:51:24,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 999/5000 [32:53<2:36:20,  2.34s/it][2017-01-06 17:03:36,225] Making new env: MountainCar-v0\n",
      "[2017-01-06 17:03:36,238] Attempted to wrap env <MountainCarEnv instance> after .configure() was called. All wrappers must be applied before calling .configure()\n",
      "[2017-01-06 17:03:36,240] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-06 17:03:38,569] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alexajax/Downloads/goto/records')\n",
      " 20%|██        | 1000/5000 [32:58<3:27:22,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -200.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1207/5000 [42:46<2:29:10,  2.36s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-54c86548b289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexajax/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexajax/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in tqdm(range(5000)):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    for i in range(10):\n",
    "        pool.update(SEQ_LENGTH,append=True,)\n",
    "    for i in range(10):\n",
    "        loss = train_step()\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%500 ==0:\n",
    "        n_games = 10\n",
    "        action_layer.epsilon.set_value(0)\n",
    "        rewards[epoch_counter] = pool.evaluate( record_video=False,n_games=n_games,verbose=False)\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(n_games,np.mean(rewards[epoch_counter])))\n",
    "        action_layer.epsilon.set_value(0.05)\n",
    "    \n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-200.0, -200.0, -200.0]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(np.mean,session_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda k:k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11835a780>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b37208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(iters),list(map(np.mean,session_rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-06 17:13:41,206] Making new env: MountainCar-v0\n",
      "[2017-01-06 17:13:41,217] Attempted to wrap env <MountainCarEnv instance> after .configure() was called. All wrappers must be applied before calling .configure()\n",
      "[2017-01-06 17:13:41,219] Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "[2017-01-06 17:13:41,221] Starting new video recorder writing to /Users/alexajax/Downloads/goto/records/alex/openaigym.video.4.99355.video000000.mp4\n",
      "\n",
      "[2017-01-06 17:13:45,083] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/alexajax/Downloads/goto/records/alex')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=-200.0\n"
     ]
    }
   ],
   "source": [
    "trained_reward = pool.evaluate(save_path=\"./records/alex\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
